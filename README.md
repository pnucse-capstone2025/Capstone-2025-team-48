[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/nRcUn8vA)

# 1. 프로젝트 배경
최근 프로축구 및 아마추어 축구 모두에서 전술 분석은 매우 중요한 요소가 되고 있습니다. 과거에는 코치와 전술 분석관이 수작업으로 축구 영상을 돌려보며 전술을 파악했지만, 이는 시간과 인력이 많이 소모되는 방식이었습니다. 인공지능과 컴퓨터 비전 기술이 발전하면서, 데이터 기반 스포츠 분석의 필요성이 높아졌고, 이로 인해 영상 기반 자동 분석이 주목받고 있습니다. 

딥러닝 기반 객체와 추적 알고리즘이 고도화되고 있습니다. 예시로 딥러닝 기반 객체 탐지에는 YOLO, Faster R-CNN등이 있고, 추적 알고리즘에는 ByteTrack, SORT, DeepSORT등이 있습니다. 이처럼 컴퓨터 비전과 AI 기술의 발전으로 경기장에서 선수 위치, 움직임, 패스 경로 등을 자동으로 추출할 수 있게 되었습니다. 

이를 통해 경기 전체의 전술적 패턴을 수치화하여 분석하는 시도과 활발히 진행되고 있습니다. 때문에 스포츠 산업 내 AI 기술 활용이 확대되고 있습니다. 프로 구단뿐만 아니라 대학팀, 아마추어 리그에서도 경기력 향상을 위해 AI를 이용한 영상 분석을 필요로 하고 있습니다.

## 1.1. 국내외 시장 현황 및 문제점
### 국내외 시장 현황
AI 기술의 발전으로 국내외 프로축구 및 아마추어 축구 시장에서는 AI를 활용한 전술 분석이 활발히 이루어지고 있습니다.  

- **국내 사례**  
  - 대표적으로 **BEPRO data**가 있으며, K리그 1·2부에서 활용되고 있습니다.  
  - 선수 및 경기 데이터를 기반으로 다양한 분석을 제공합니다.  

- **국외 사례**  
  - **Tactic AI, Wyscout, Catapult, Pixellot, PlaymakerAI** 등 다양한 솔루션이 존재합니다.  
  - 이 중 **Tactic AI**가 대표적으로 활용되고 있으며, DeepMind와 리버풀 FC의 협력을 통해 개발되었습니다.  
  - 선수 추적 데이터를 기반으로 위치, 움직임, 패스 연결망 등을 분석하고 전술 패턴을 도출합니다.  
  - 실제 코치들의 평가에서도 인간 전문가보다 더 효과적인 전술 분석을 제공하는 것으로 인정받고 있습니다.  

### 문제점
하지만 기존 축구 경기 분석에는 다음과 같은 한계가 존재합니다.

- **접근성 문제**: 일반 구단이나 아마추어 팀에서는 사용하기 어렵습니다.  
- **비용 문제**: 솔루션 도입 및 유지 비용이 매우 높습니다.  
- **활용성 문제**: 전문가들이 보조 도구로 활용하는 수준에 머물러 있어 일반 사용자에게는 사용하기 어렵습니다.  



## 1.2. 필요성과 기대효과
 
- **AI 기반 분석**을 통해 코칭 질의 불평등 문제를 해소할 수 있습니다.  
- **소규모 동아리나 코치가 없는 팀도** 손쉽게 전술 분석과 코칭을 제공받을 수 있습니다.  
- **자동화된 데이터 처리와 분석 기능**을 통해 데이터 준비 및 전술 분석에 소요되는 시간을 크게 단축할 수 있습니다.  
# 2. 개발 목표
## 2.1. 목표 및 세부 내용
이번 연구의 목표는 축구 경기 영상으로 선수 트래킹을 중심으로 전술 분석을 할 수 있도록 하고, 각 선수별로 선수의 팀 소속, 팀 간 간격 유지 여부, 포지션별 밀집도와 같이 선수의 포지션 및 필드 라인 기반 분석을 하려고 합니다. 딥러닝 기반 객체 추적 및 분석 기법을 활용하여, 영상 속에서 선수의 위치와 팀, 전술 등을 식별하는 것을 목표로 하고 있습니다.

본 프로젝트는 웹 기반 축구 영상 전술 분석 시스템을 개발하는 것을 목표로 합니다. 사용자가 웹 인터페이스를 통해 축구 경기 영상을 업로드하면, 서버에서 딥러닝 비전 모델을 이용해 영상 속 선수들을 자동으로 탐지 및 추적합니다. 분석이 완료된 영상은 웹페이지에서 즉시 확인하고, 결과 파일을 직접 다운로드할 수 있는 기능을 제공합니다.




## 2.2. 기존 서비스 대비 차별성 
 현재 글로벌 시장에서는 Tactic AI, Wyscout, Catapult, Pixellot, PlaymakerAI 등 다양한 축구 분석 솔루션이 존재합니다. 이들 대부분은 고가의 장비(트래킹 센서, 고해상도 카메라 등)나 구독 기반 서비스에 의존하기 때문에, 프로 구단이나 재정적으로 여유 있는 팀 위주로 사용되는 경향이 있습니다. 국내에서도 비프로(Bepro)와 같은 데이터 분석 플랫폼이 존재하지만, 아직까지는 K리그 일부 구단이나 프로 레벨에 한정된 서비스에 머무르고 있습니다.  

본 프로젝트의 차별성은 다음과 같이 요약할 수 있습니다:
- **웹 기반 접근성** – 단순히 웹 브라우저와 인터넷만 있으면 별도의 장비나 고비용 라이선스 없이도 누구나 쉽게 분석을 수행할 수 있습니다.  
- **경량화된 AI 모델** – YOLOv8n, MobileNet, LSTM을 적절히 결합하여 높은 정확도를 유지하면서도 처리 속도와 비용을 최적화했습니다.  
- **분석 속도 개선** – ByteTrack을 통한 추적 기법을 활용하여 실시간에 가까운 전술 분석 피드백을 제공합니다. 

따라서 본 프로젝트는 기존 서비스 대비 저비용과 사용자 편의성이라는 측면에서의 차별성을 가지고 있습니다.  

## 2.3. 사회적 가치 도입 계획 
> 본 프로젝트는 단순히 기술적인 성과를 넘어 **사회적 가치** 창출을 지향합니다.  

- **공공성 확대**  
  아마추어 리그·청소년 클럽 등도 전술 분석의 기회를 가질 수 있도록 접근 장벽을 낮췄습니다. 이는 축구 저변 확대와 공정한 경쟁 환경 조성에 기여합니다.  
- **지속 가능성**  
  클라우드 및 경량화된 AI 모델을 사용함으로써 시스템 유지·운영에 필요한 리소스를 줄였고, 장기적으로 누구나 활용 가능한 지속 가능한 스포츠 분석 데이터를 제공합니다.  
  대규모 장비나 고사양 서버 없이도 운영이 가능하기 때문에, 불필요한 에너지 소비를 최소화할 수 있습니다. 데이터 전송과 저장 또한 클라우드 기반으로 최적화되어 있습니다.
- **교육적 가치**  
  청소년 선수들이 자신의 플레이 데이터를 쉽게 확인하고 학습에 활용할 수 있으며, 지도자들은 이를 통해 데이터 기반 피드백을 제공할 수 있습니다.  

# 3. 시스템 설계
## 3.1. 시스템 구성도
> 웹페이지 라우팅 구조를 나타내는 구성도입니다.

<img width="940" height="506" alt="image" src="https://github.com/user-attachments/assets/f2140552-f663-4506-8787-4b6b3783230e" />

<br/>

> 비전 머신러닝 모델 처리 구조입니다.

<img width="1143" height="622" alt="Image" src="https://github.com/user-attachments/assets/514f6e4f-be7c-4b9a-bf0a-c3824bf169e6" />


## 3.2. 사용 기술
- **FastAPI** : FastAPI는 현대적이고, 빠르며, 파이썬 표준 타입 힌트에 기초한 Python의 API를 빌드하기 위한 웹 프레임워크입니다. Node.js 및 Go와 대등할 정도로 매우 높은 처리 성능을 제공하고 있다. 매우 직관적으로 사용하기 쉽고, 코드 중복을 최소화하도록 설계되었다.

- **YOLOv8n** : YOLO (You Only Look Once)는 실시간 객체 검출 시스템으로, CNN(Convolutional Neural Networks) 딥러닝 모델을 기반으로 특징을 추출한 뒤 이를 이용해서 물체의 종류와 위치를 Bounding Box 로 표시해 Label로 분류한다.
- **웹 프레임워크** : 웹 프레임워크는 동적인 웹 페이지나 웹 애플리케이션을 효율적으로 개발할 수 있도록 구조와 기능을 제공하는 소프트웨어 도구이다. 웹 사이트를 처음부터 직접 구현하려면 HTTP 요청/응답 처리, 라우팅, 데이터베이스 연결, 보안 처리 등 복잡한 기능을 전부 개발해야 하는데, 프레임워크는 이를 미리 구현해두어 개발자가 핵심 기능에 집중할 수 있게 도와준다.

- **MobileNet(모바일넷)** : MobileNet은 구글(Howard et al., 2017)에서 제안한 경량 딥러닝 신경망 구조로, 스마트폰이나 임베디드 기기처럼 계산 자원이 제한된 환경에서 효율적으로 동작할 수 있도록 설계되었다. 기존의 합성곱 신경망(CNN)은 높은 정확도를 보장하지만, 연산량이 많고 모델 크기가 커서 모바일 환경에서 활용하기 어렵다는 한계가 있었다. MobileNet은 이를 해결하기 위해 Depthwise Separable Convolution이라는 연산 방식을 도입하여 연산량과 파라미터 수를 획기적으로 줄였다.
- **LSTM(Long Short-Term Memory)** : LSTM(Long Short-Term Memory)은 1997년 Hochreiter와 Schmidhuber가 제안한 순환 신경망(Recurrent Neural Network, RNN)의 한 종류이다. 기존 RNN은 시계열 데이터나 연속적인 데이터를 처리하는 데 적합하지만, 긴 시퀀스를 다룰 때 기울기 소실(vanishing gradient) 문제와 장기 의존성(long-term dependency) 학습의 어려움이 발생한다. LSTM은 이러한 한계를 극복하기 위해 **메모리 셀(cell state)**과 게이트(gate) 구조를 도입하여, 중요한 정보는 오래 기억하고 불필요한 정보는 망각할 수 있도록 설계되었다.


# 4. 개발 결과
## 4.1. 전체 시스템 흐름도
<img width="399" height="516" alt="Image" src="https://github.com/user-attachments/assets/e7ac50b3-d49e-46ca-b1e1-1d8ac3412c08" />

### 1. 영상 업로드
- 사용자가 웹 페이지에 접속해 **축구 영상을 업로드**합니다.

### 2. 분석 시작  
- **분석 시작 버튼**을 눌러 축구 전술 분석을 실행합니다.

### 3. 영상 분석 진행
- 시스템이 영상을 처리하여 **선수 위치 데이터를 추출**합니다.  
- 실시간 위치 데이터를 기반으로 **포메이션 및 전술 분석**을 수행합니다.

### 4. 분석 결과 확인
- 분석이 완료된    제공됩니다.  
- 영상에는 **선수들의 위치와 전술 분석 결과**가 시각화되어 표시됩니다.

### 5. 결과 다운로드
- 사용자는 분석이 완료된 영상을 **다운로드하여 개인 소장**할 수 있습니다.
## 4.2. 기능 설명 및 주요 기능 명세서
- **프론트엔드** : 본 프로젝트의 프론트엔드는 단일 TML 문서 내에 정적 마크업(HTML), 스타일(CSS), 동적 행위(JavaScript)를 결합한 구조로 구현되었다. 배포 단순성과 재현성을 확보하였다. 핵심 목표는 사용자가 영상 파일을 쉽게 업로드하고, 분석 진행 상태를 확인하며, 결과 영상을 재생하고 전술적 포메이션을 확인할 수 있도록 하는데 있다.
  
- **화면 구조와 스타일** : 레이아웃은 좌측 사이드바와 우측 메인 영역으로 구성되어져 있다. 메인 영역은 3개의 파트로 구분되어지는데: 1. 영상 업로드, 2. 분석 설정, 3. 분석 결과로 구성되어져 있다. 우측 상단에는 ‘새 분석’ 버튼으로 영상 초기화하는 버튼이 있다. 업로드 박스는 drag & drop으로 하여 사용자가 편하게 업로드 할 수 있도록 하였다. 2번째인 분석 설정에서 영상에 대한 분석을 설정하고 “분석 시작” 버튼을 눌러 분석을 시작하고, 3번째 분석 결과에서 영상에 대한 분석 결과를 보여준다.
  <img width="940" height="462" alt="image" src="https://github.com/user-attachments/assets/d03326eb-379d-4a2f-bdb2-0fbde8b1c0f4" />
  <img width="940" height="388" alt="image" src="https://github.com/user-attachments/assets/1980d158-27dc-4fa0-a249-28ff83fd05f8" />
  <img width="940" height="312" alt="image" src="https://github.com/user-attachments/assets/caecb17a-a269-49c5-a96e-254117ee396f" />
  
- **선수 객체 탐지(YOLOv8n 모델 사용)** : 첫번째 단계는 Ultralytics의 YOLO모델을 사용하여 각 선수를 탐지하는 것 입니다. 각 선수를 보다 높은 정확도로 탐지하기 위해 선수만을 탐지하는 모델로 fine-tuning 작업을 진행하였습니다. Fine-tuning 작업을 위해 먼저 데이터 전처리 과정을 겨쳤습니다. 축구 영상을 프레임별로 나누고, 라벨링 파일(JSON형식)을 파싱하여 모델 학습용 라벨링(txt형식)으로 변환하였습니다. 이후 모델학습을 진행하였고, 탐지 개선도는 다음과 같습니다.

  | 구분              | 장면1 | 장면2 | 장면3 | 장면4 | 장면5 | 평균   |
  |-------------------|-------|-------|-------|-------|-------|--------|
  | 기본 YOLO 모델    | 6/20  | 11/19 | 18/22 | 17/20 | 15/21 | 70.1%  |
  | Fine-tuning된 YOLO 모델 | 18/19 | 22/22 | 20/20 | 21/21 | 21/21 | 98.9%  |

  약 28퍼센트 정확도 개선되었습니다.
  
  <img width="914" height="521" alt="image" src="https://github.com/user-attachments/assets/70208353-2a70-40e7-a04c-26e82a239e22" />

  Yolov8n 기본 모델 탐지 결과

  <img width="940" height="531" alt="image" src="https://github.com/user-attachments/assets/12a1d1c6-94c1-4343-bef7-0c94464db90b" />

  Fine-tuning된 모델 탐지 결과

- **MobileNet** : 이미지 분석에 사용되는 경량 CNN모델 MobileNet을 사용하여 각 팀을 식별했습니다.

  YOLO 모델 하나로 선수 식별과 팀 분류를 동시에 하지 않은 이유는 다음과 같습니다.
  1.	모델 분리로, 개선이 필요한 모델만 따로 학습시켜 비용을 절감 할 수 있다.
  2.	YOLO모델 자체로 전부 학습을 시키면 이후 식별 시 한 화면에 3개 이상의 팀이 식별 될 수 있다.
  3.	YOLO의 ByteTrack을 활용하여 Tracking을 시작할 때만 MobileNet을 사용해 팀을 분류하기 때문에 컴퓨팅 파워가 절약되고 속도가 빨라진다.
  위 까닭으로 YOLO는 선수 식별, MobileNet은 팀 구별을 담당시켜 개발하였습니다.

  MobileNet 대신 바운딩박스 내 유니폼 색깔 구별방법이나, 컬러 클러스터링을 활용한 구별 기법도 테스트해 보았으나 정확도가 너무 낮아 실패하였던 시행착오를 거쳤습니다.    MobileNet 학습법은 다음과 같습니다.

  먼저 영상에서 선수 바운딩 박스를 추출해내 팀 선수별 데이터를 준비하였습니다.
<img width="722" height="453" alt="image" src="https://github.com/user-attachments/assets/c0126c08-9972-4833-a316-6761b2d4c056" />

  흰색 유니폼의 서울팀 선수

<img width="713" height="505" alt="image" src="https://github.com/user-attachments/assets/cb81c63e-1bd8-43f3-96a1-8e5ed0eca524" />

  초록 유니폼의 전북팀 선수

<img width="717" height="501" alt="image" src="https://github.com/user-attachments/assets/1495557b-d3b2-40e0-a5bd-7458785d22e1" />

  검은 옷의 심판

  각팀 2000장 이상, 심판 600장을 MobileNet에 학습시켜 바운딩박스의 선수를 탐지하는 모델을 학습시켰습니다.
<img width="458" height="458" alt="image" src="https://github.com/user-attachments/assets/60705642-9a86-4732-b67b-1d43f69a33a5" />

  총 10 Epoch을 거쳐 학습시켰습니다.

- **YOLO와 MobileNet 통합작업** : YOLO는 선수 탐지, MobileNet은 팀 분류 역할을 담당합니다.
하지만 YOLO의 predict 기능을 사용해서 객체를 탐지하고, 이를 각각 MobileNet에서 분류하게 되면 많은 컴퓨팅 자원을 소모하게 됩니다.
따라서 YOLO의 객체 트레킹 기능인 ByteTrack기능을 활용하여 한 번 탐지한 객체는 최대한 같은 객체로 인식하게끔 설정합니다.
ByteTracking이 동작하기 시작할 때 MobileNet을 통해 딱 한 번 탐지하여 컴퓨팅 자원의 소모를 획기적으로 줄였습니다.
0~60frame 분석 소요시간			  (단위: 초)

| 구분              | 소요시간 (초) |
|-------------------|---------------|
| Predict + 팀 분류 | 100.79        |
| Track + 팀 분류   | 17.68         |
약 5.7배 성능 개선

  MobileNet사용 팀 분류 성능 측정표 (임의의 장면 수동 측정)
(단위: 팀과 선수가 옳게 식별됨/화면에 보이는 모든 선수)

| 장면 1 | 장면 2 | 장면 3 | 장면 4 | 장면 5 |
|:------:|:------:|:------:|:------:|:------:|
| 11/22  | 18/22  | 17/21  | 17/20  | 17/18  |

약 60% 정확도

<img width="482" height="271" alt="image" src="https://github.com/user-attachments/assets/97dc24c5-07ee-4d23-b056-42d97779bf1c" />

MobileNet을 활용한 팀 식별 (장면 1)

- **LSTM을 활용한 전술예측** : 전술분석을 하기 위해 먼저 라벨링 데이터 전처리 과정을 거쳤습니다.

<img width="452" height="389" alt="image" src="https://github.com/user-attachments/assets/4a61dfd6-0984-4890-8ad0-d5e1eb44585b" />

프레임 내 선수 위치

<img width="438" height="389" alt="image" src="https://github.com/user-attachments/assets/94c4d143-6040-424e-b14d-1536a5982139" />

프레임 구간 간 사용 전술

두 csv 파일을 활용해 LSTM 모델을 학습시켰습니다.

<img width="774" height="432" alt="image" src="https://github.com/user-attachments/assets/71bc8e81-6d85-4221-9903-770f2c419b5b" />

LSTM모델 분석을 통해 왼쪽 위에 예측된 전략이 표시됩니다.


- **FastAPI** : 본 프로젝트에서 프론트엔드 웹사이트와 AI 분석 모델을 연결하기 위해 Python 기반의 FastAPI 프레임워크를 서버로 활용하였다. FastAPI는 코드의 가독성과 유지보수성을 높이는 동시에 자동 문서화(Swagger UI)를 지원하는 경량 웹 프레임워크이다. 이를 통해 직관적으로 설계하고, 프론트엔드와의 데이터 교환을 체계적으로 관리할 수 있다. 프로젝트에서 FastAPI을 활용하여 자동 문서화와 타입 기반 코드 검증을 통해 개발 효율성을 향상시켰다. 프론트엔드에서 상태 폴링 방식으로 요청하는 동안 서버가 효율적으로 상태를 업데이트하고, 결과 데이터를 반환할 수 있어 실시간성을 보장할 수 있었다. 이처럼 본 연구에서 FastAPI는 프론트엔드 – AI 모델 – 데이터베이스를 연결하는 중간 역할을 담당하며, RESTful 구조를 기반으로 안정적인 데이터 교환을 보장한다는 점에서 적합한 웹 프레임워크이다. 

| Name         | Router          | 설명 |
|--------------|-----------------|------|
| 메인 페이지 | `/`             | 단일 페이지 애플리케이션(SPA)으로, 새 분석 시작/영상 업로드/분석 결과 확인을 제공 |
| 영상 업로드 | `/api/upload`   | 사용자가 업로드한 영상을 서버에 저장하고 `file_id`, `video_url`을 반환 |
| 분석 요청   | `/api/analyze`  | 업로드된 영상과 팀/심판 설정값을 바탕으로 새로운 분석 작업을 생성하고 `job_id` 반환 |
| 분석 상태 조회 | `/api/status/{id}` | 지정된 작업(`job_id`)의 상태와 진행률을 반환 (queued, running, done, error) |
| 분석 결과 조회 | `/api/result/{id}` | 분석 완료 후 결과 영상 URL, 포메이션, 전술 요약, 선수 좌표 등 세부 데이터를 반환 |
| 정적 파일 접근 | `/static/...`   | 업로드된 원본 영상, 분석 결과 영상·이미지 등 정적 리소스 접근 경로 |
| 정적 파일 접근 | `/uploads/...`  | 정적 리소스 접근 경로 |

## 4.3. 디렉토리 구조
>
## 4.4. 산업체 멘토링 의견 및 반영 사항
프로젝트 진행 과정에서 산업체 멘토링을 통해 피드백을 받았으며, 이를 실제 구현 단계에서 적극적으로 반영하였다. 우선, 정확도 향상에 대한 조언을 바탕으로 기존 YOLO 모델을 그대로 사용하는 대신, 축구 경기 데이터셋에 맞추어 Fine-Tuning을 진행하였다. 이를 통해 선수 탐지 정확도가 기존 대비 약 28% 개선되었고, 실제 경기 상황에서도 안정적으로 선수 식별이 가능해졌다.


또한, 분석 속도 개선과 관련하여 멘토는 실제 경기 분석에서 중요한 것은 단순히 높은 정확도뿐만 아니라 실시간성이라고 지적하였다. 이에 따라 YOLO 모델의 탐지 결과를 매 프레임마다 MobileNet에 전달하는 기존 방식 대신, ByteTrack 기반의 추적 기법을 도입하였다. 그 결과, 동일 구간(0~60 프레임) 분석 시간이 약 100초에서 17초로 줄어들어, 약 5.7배의 속도 개선을 달성하였다. 이는 멘토의 피드백을 직접 반영하여 성능과 실시간성을 동시에 확보한 대표적인 사례이다.

사용자 경험(UI/UX) 측면에서도 멘토링 피드백이 크게 기여하였다. 초기 버전은 분석 결과를 단순히 수치 데이터 형태로만 제공했으나, 멘토는 “실제 현장 사용자는 데이터보다는 직관적인 시각화와 간단한 요약을 원한다”는 점을 강조하였다. 이에 따라 웹 프론트엔드 화면에 포메이션 시각화, 전술 요약 텍스트, 분석 결과 영상 재생 기능을 추가하였다. 이로써 전문 분석관뿐만 아니라 아마추어 지도자와 선수들도 분석 결과를 쉽게 이해하고 활용할 수 있도록 개선하였다.

마지막으로, 멘토는 프로젝트의 확장 가능성과 지속 가능 측면에서 피드백을 주었다. 현재는 제한된 데이터셋과 특정 모델만을 기반으로 하지만, 향후 다양한 리그·팀 데이터를 확보하고, 모델 최적화를 통해 더 많은 환경에서도 안정적으로 작동할 수 있어야 한다는 점을 강조하였다. 이에 팀은 추후 연구 방향으로 대규모 데이터셋 확장과 멀티모달 분석(영상 + 센서 데이터 결합)을 계획에 포함시켰다.

결과적으로 산업체 멘토링을 통해 프로젝트는 단순한 기술 시연을 넘어, 정확도 향상 – 실시간성 확보 – 사용자 친화적 인터페이스 – 확장성 고려라는 네 가지 중요한 발전 방향을 얻게 되었으며, 이는 실제 서비스로 발전할 수 있는 기반을 마련하는 데 큰 도움이 되었다.

# 5. 설치 및 실행 방법
>
## 5.1. 설치절차 및 실행 방법
1. 터미널에서 soccer_predicter로 이동

2. 터미널에서 python -m uvicorn main:app --reload 입력

3. 새 터미널에서 start index5.html 입력

# 6. 소개 자료 및 시연 영상
## 6.1. 프로젝트 소개 자료
> [발표ppt](https://github.com/user-attachments/files/22613007/ppt.pdf)
## 6.2. 시연 영상
[![Image](https://github.com/user-attachments/assets/55cfc47b-f4d9-463d-a09f-795472cd84cf)](https://www.youtube.com/watch?v=YcgTPpjReJk)

# 7. 팀 구성
## 7.1. 팀원별 소개 및 역할 분담
| 학번      | 이름   | 역할 분담 |
|-----------|--------|-----------|
| 202245821 | 안성수 | **축구 영상 분석 모델 설계 및 구현**<br> - Fine-Tuning된 YOLO 모델과 ByteTrack을 활용하여 선수 탐지 및 추적 알고리즘 구현<br> - 객체 탐지 및 추적 알고리즘 적용, 선수 움직임 데이터 추출<br> - 선수 탐지와 MobileNet 기반 팀 분류 모델을 분리하여 분석 최적화 및 기초 데이터 가공<br> **전술 분석 로직 개발 및 데이터 처리 파이프라인 구축**<br> - LSTM 기법을 활용한 전술 예측 모델 개발<br> - 영상 입력부터 분석 결과 산출까지 자동화된 데이터 처리 파이프라인 구축 |
| 201824475 | 박성재 | **UI 설계 및 디자인**<br> - 요구 사항을 바탕으로 UI 설계서 작성<br> **프론트엔드 개발**<br> - 웹 서비스 UI 구현<br> - HTML, CSS, JavaScript, React를 활용한 웹 브라우저 구현<br> - 동영상 업로드 기능 제작<br> **백엔드 개발**<br> - FastAPI를 활용하여 웹 페이지와 AI 모델 연동 기능 구현 |
## 7.2. 팀원 별 참여 후기
- 202245821 안성수

>프로젝트 초반, YOLO 모델이 아무런 오류 없이 학습되지 않았을 때가 가장 기억에 남습니다. 이틀 밤낮을 꼬박 원인을 찾아 헤맸고, 결국 문제는 복잡한 코드가 아닌 이미지와 레이블 파일의 이름이 일치하지 않는 아주 기본적인 데이터 정합성 문제였습니다. 이 경험을 통해 화려한 기술을 적용하기 전에 데이터의 기초부터 꼼꼼히 살피는 자세가 얼마나 중요한지 뼈저리게 느꼈습니다.
>
>선수들의 팀을 유니폼 색으로 구분하는 기능은 또 다른 도전이었습니다. 처음에는 단순히 색상 영역을 추출하는 간단한 방법들을 시도했지만 정확도는 50%를 넘기기 어려웠습니다. 여러 번의 실패 끝에, 기존의 방식을 고집하기보다 MobileNet 기반의 강화학습이라는 새로운 접근법을 도입하여 문제를 해결할 수 있었습니다. 이 과정에서 한 가지 방법에 얽매이지 않고 문제의 본질을 파악해 더 나은 기술을 선택하는 유연함의 중요성을 배울 수 있었습니다.
>
>물론 수많은 에러와 씨름하며 밤을 새우는 날도 많아 힘들기도 했습니다. 하지만 AI가 코드를 짜주는 시대에도 결국 문제의 본질을 파악하고, 끈질기게 해결의 실마리를 찾아 나서는 것은 개발자의 몫이라는 것을 다시 한번 깨달았습니다. 막막했던 문제들이 하나씩 해결될 때마다 큰 성취감을 느꼈고, 이번 프로젝트는 저를 기술적으로나 정신적으로 한 뼘 더 성장하게 만든 소중한 경험이었습니다.
>
>팀원과의 협업 과정에서 몇 가지 어려움을 겪으며 소통의 중요성을 다시 한번 깨달았습니다. 특히, 저희가 정의한 결과물의 완성도에 대한 기대치가 달라 이를 조율하는 과정이 필요했습니다. 예를 들어, 보고서의 초기 버전은 제가 내용을 더 구체화하고 다듬는 방향으로 보완해야 했습니다.
>
>또한, 웹사이트 개발 과정에서는 각자 담당한 부분의 코드를 통합하고 연결하는 단계에서 소통의 문제가 있었습니다. 프로젝트의 원활한 마무리를 위해 제가 최종적으로 통합 작업을 책임지고 완성하며 기술적인 완성도를 높일 수 있었습니다.
>
>이러한 경험을 통해 팀 프로젝트에서는 명확한 소통과 역할에 대한 지속적인 합의가 얼마나 중요한지 배울 수 있었습니다. 힘든 점도 있었지만, 덕분에 문제 해결 능력과 책임감을 기를 수 있었던 귀중한 성장통이었다고 생각합니다.


- 201824475  박성재
>이번 프로젝트에서 저는 주로 UI 설계와 프론트엔드, 그리고 FastAPI를 활용한 백엔드 연동을 담당했습니다. 처음에는 단순히 화면에 데이터를 표시하는 수준의 웹 페이지를 구현하면 될 것이라고 생각했지만, 실제 개발 과정은 훨씬 더 복잡하고 세밀한 고려가 필요했습니다. 특히 영상 업로드 기능과 분석 요청 과정을 구현하면서 서버와 클라이언트 간의 데이터 형식 차이, 대용량 파일 처리 문제 등 다양한 오류를 경험하였고, 이를 해결하기 위해 수많은 테스트와 디버깅을 반복해야 했습니다. 이 과정에서 단순히 동작하는 코드를 작성하는 것이 아니라, 안정적이고 신뢰성 있는 서비스를 만드는 것이 얼마나 중요한지를 깊이 느낄 수 있었습니다.  
>
>FastAPI와 React를 통한 연동 작업은 제게 큰 어려움이었습니다. 기존에는 단순한 정적 웹 구현 경험만 있었으나, 이번 프로젝트에서는 REST API를 기반으로 한 비동기 통신, 상태 관리, 데이터 직렬화와 같은 개념들을 실무적으로 다루어야 했습니다. 예를 들어, 분석 요청 이후 서버가 결과를 반환하기까지 시간이 오래 걸리는 문제를 해결하기 위해, 단순 응답 대기 방식 대신 상태 조회 API를 주기적으로 호출하는 폴링 방식을 구현했습니다. 이러한 시도는 사용자 경험을 개선하는 동시에, 실제 서비스 아키텍처 설계에서 고려해야 할 중요한 요소라는 점을 체감하게 해주었습니다.  
>
>사용자 경험(UI/UX) 측면에서도 많은 고민을 했습니다. 이 프로젝트의 주요 사용자는 프로 코치뿐만 아니라 아마추어 지도자나 청소년 선수일 수 있기 때문에, 지나치게 복잡한 기능보다는 직관적이고 간단한 흐름이 필요했습니다. 따라서 영상 업로드 → 분석 요청 → 결과 확인이라는 세 단계의 명확한 흐름을 중심으로 인터페이스를 구성하고, 분석 결과를 단순한 수치가 아닌 포메이션 시각화와 요약 텍스트로 제공하도록 설계했습니다. 이러한 개선을 통해 실제 사용자가 처음 접하더라도 서비스 활용에 어려움을 느끼지 않도록 만들 수 있었습니다.  
>
>협업 과정 또한 중요한 배움의 기회였습니다. 안성수 팀원이 AI 모델 개발을 맡고 있었기 때문에, 제가 구현한 프론트엔드가 그의 백엔드 API와 원활히 연동될 수 있도록 지속적인 소통이 필요했습니다. 예를 들어, API 응답 형식이 바뀌었을 때 즉시 프론트엔드 로직도 수정해야 했는데, 이 과정에서 버전 관리와 협업 도구의 중요성을 크게 느꼈습니다. 또한 일정 조율 과정에서는 각자의 작업 속도 차이가 존재했지만, 중간 점검과 테스트 회의를 통해 문제를 조기에 발견하고 해결할 수 있었습니다. 이는 단순히 기술적인 능력뿐만 아니라, 협업 능력이 프로젝트 성공에 얼마나 큰 영향을 미치는지를 깨닫게 해주었습니다.
>
>종합적으로, 이번 프로젝트는 단순한 학부 과제를 넘어 실제 서비스 개발에 가까운 경험을 제공했으며, 저는 그 과정에서 기술적 역량, 문제 해결 능력, 협업 능력 모두를 성장시킬 수 있었습니다.


# 8. 참고 문헌 및 출처
[GwangMin HAN “Study of a Real-time Analysis for Soccer Play by Intelligent-recognition Model for Sports-industry”](https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE10666809)

